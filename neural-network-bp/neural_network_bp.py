import os
from tkinter import X
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Saves the bias and weights for the given network to csv files named after the size of the matrices.
def save_bias_weights(network):
    folder = "nn_saved/"
    print("saving bias and weights")

    for i in range(len(network.biases)):
        np.savetxt(folder + "b{}_hls{}.csv".format(i+1, network.a1.size), network.biases[i], delimiter=",")

    for i in range(len(network.weights)):
        np.savetxt(folder + "w{}_hls{}.csv".format(i+1, network.a1.size), network.weights[i], delimiter=",")

# Loads the bias and weights for a network if there's a csv file matching the dimensions of the matrices.
def load_bias_weights(network):
    print("loading bias and weights")
    folder = "nn_saved/"
    for i in range(len(network.biases)):
        filepath = folder + "b{}_hls{}.csv".format(i+1, network.a1.size)
        if os.path.exists(filepath):
            bias = np.loadtxt(filepath, delimiter=",", ndmin=2)
            if bias.shape == network.biases[i].shape:
                print("valid saved bias exists: ", filepath)
                np.copyto(network.biases[i], bias)

    for i in range(len(network.weights)):
        filepath = folder + "w{}_hls{}.csv".format(i+1, network.a1.size)
        if os.path.exists(filepath):
            weight = np.loadtxt(filepath, delimiter=",", ndmin=2)
            if weight.shape == network.weights[i].shape:
                print("valid saved weights exists: ", filepath)
                np.copyto(network.weights[i], weight)

# Loads the waldo and not waldo reduced features generated by PCA into one matrix
# shuffles the order and splits them into training, testing and validation subsets.
def load_waldo_data(training_size_percent, testing_size_percent):
    print("loading waldo data")

    with open('features_waldo.csv', 'r') as f:
        x_waldo = np.loadtxt(f, delimiter=',')

        # waldo label is [1,0]
        y_waldo = np.ones(shape=(x_waldo.shape[0], 1))
        y_waldo = np.append(y_waldo, np.zeros([len(x_waldo), 1]), axis=1)

    with open('features_notwaldo.csv', 'r') as t:
        x_notwaldo = np.loadtxt(t, delimiter=',')

        #not waldo label is [0,1]
        y_notwaldo = np.zeros(shape=(x_notwaldo.shape[0], 1))
        y_notwaldo = np.append(y_notwaldo, np.ones([len(x_notwaldo), 1]), axis=1)

    # combine the two matrices into one
    x_mixed = np.append(x_waldo, x_notwaldo, axis=0)
    y_mixed = np.append(y_waldo, y_notwaldo, axis=0)

    # set the random seed to get the same result every run
    np.random.seed(0)

    # get the row count of the matrix
    rows = x_mixed.shape[0]

    # shuffle the rows of the matrix
    randomize = np.arange(len(x_mixed))
    np.random.shuffle(randomize)
    x_mixed = x_mixed[randomize]
    y_mixed = y_mixed[randomize]

    # calculate the last row index of the training and testing samples
    last_row_training = int(rows * training_size_percent / 100)
    last_row_testing = last_row_training + int(rows * testing_size_percent / 100)

    # slice the matrix into three by using the row indexes
    x_train = x_mixed[:last_row_training]
    y_train = y_mixed[:last_row_training]
    x_test = x_mixed[last_row_training:last_row_testing]
    y_test = y_mixed[last_row_training:last_row_testing]
    x_valid = x_mixed[last_row_testing:]
    y_valid = y_mixed[last_row_testing:]

    print("sample sizes: data: ", x_mixed.shape, " training: ", x_train.shape, " test:", x_test.shape,
          " validation:", x_valid.shape)
    x_train, x_test, y_train, y_test

    return x_train, x_test, x_valid, y_train, y_test, y_valid

# loads iris testing data from sklearn
def load_iris_data():
    print("loading iris data")
    # Iris
    data = load_iris()
    # Dividing the dataset into target variable and features
    X=data.data
    y=data.target
    y_new = np.empty(shape = (X.shape[0], 3))
    for i in range(0, y.shape[0]):
        if y[i] == [0]:
            y_new[i] = [1,0,0]
        elif y[i] == [1]:
            y_new[i] = [0,1,0]
        elif y[i] == [2]:
            y_new[i] = [0,0,1]
    y = y_new

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=4)

    return X_train, X_test, y_train, y_test

# loads XOR testing data
def load_xor_data():
    print("loading XOR data")
    # XOR training data
    x_sample = np.array([
        [0, 0],
        [0, 1],
        [1, 0],
        [1, 1],
    ])
    # XOR expected labels
    y_sample = np.atleast_2d([0, 1, 1, 0]).T

    return x_sample, y_sample

# the main class containg all the neural network code
class Network:

    # constructor for the neural network that creates the neural network with the specified dimensions
    def __init__(self, input_layer_size, hidden_layer_count, hidden_layer_size, output_layer_size, batch_size):

        # activation neurons for each layer
        self.a0 = np.zeros(shape=(batch_size, input_layer_size))
        self.a1 = np.zeros(shape=(batch_size, hidden_layer_size))
        self.a2 = np.zeros(shape=(batch_size, output_layer_size))

        self.activation_layers = [self.a0, self.a1, self.a2]
        
        # randomizes starting values for weights and biases to values between 0.1 and 1.0 
        # to prevent any single weight or bias from being adjusted doing backpropagation
        self.w1 = np.random.uniform(0.1, 1.0, size=(input_layer_size, hidden_layer_size))
        self.w2 = np.random.uniform(0.1, 1.0, size=(hidden_layer_size, output_layer_size))
        self.b1 = np.random.uniform(0.1, 1.0, size=(batch_size, hidden_layer_size))
        self.b2 = np.random.uniform(0.1, 1.0, size=(batch_size, output_layer_size))

        # same as above but instead the starting values are from a normal distribution with mean 0.5
        #self.w1 = np.random.normal(0.5, size=(input_layer_size, hidden_layer_size))
        #self.w2 = np.random.normal(0.5, size=(hidden_layer_size, output_layer_size))
        #self.b1 = np.random.normal(0.5, size=(batch_size, hidden_layer_size))
        #self.b2 = np.random.normal(0.5, size=(batch_size, output_layer_size))

        # same as above but weight and biases are set to values to not influence the signal being feed forward
        # useful when debugging only
        #self.w1 = np.ones(shape=(input_layer_size, hidden_layer_size))
        #self.w2 = np.ones(shape=(hidden_layer_size, output_layer_size))
        #self.b1 = np.zeros(shape=self.a1.shape)
        #self.b2 = np.zeros(shape=self.a2.shape)

        # lists of weights and biases
        self.weights = [self.w1, self.w2]
        self.biases = [self.b1, self.b2]

        # Gradients are stored in separate matrices so they can be applied after training batches
        self.w1_gradient = np.zeros(shape=self.w1.shape)
        self.w2_gradient = np.zeros(shape=self.w2.shape)
        self.b1_gradients = np.zeros(shape=self.b1.shape)
        self.b2_gradients = np.zeros(shape=self.b2.shape)
 
        # Z, sum of weighted activation + bias.
        self.z1 = np.zeros(hidden_layer_size)
        self.z2 = np.zeros(output_layer_size)

        # confusion matrix statistics
        self.accuracy = 0
        self.true_negative = 0
        self.true_positive = 0
        self.false_positive = 0
        self.false_negative = 0

    # feeds forward a single data point throughout the network 
    def feed_forward(self, x):

        # vectorize relu for easy application to numpy arrays
        relu_v = np.vectorize(lambda x: self.relu(x))

        # input layer
        # populate the input layer with the data_point
        self.a0 = x

        # hidden layer
        # calculate the weighted input with bias added of hidden layer using the output of input layer
        self.z1 = np.matmul(self.a0, self.w1) + self.b1
        # apply activation function to the output of the hidden layer
        self.a1 = relu_v(self.z1)

        # output layer
        # calculate the weighted input with bias added of output layer using activation of hidden layer
        self.z2 = np.matmul(self.a1, self.w2) + self.b2
        # apply activation to the output of the output layer
        self.a2 = relu_v(self.z2)

    # caculates the gradients for the weights and biases of the network through backpropagation
    def backpropagation(self, y):

        # vectorize the derivate of relu for easy application to numpy arrays
        d_relu_v = np.vectorize(lambda x: self.d_relu(x))

        # Partial derivatives - output layer
        # derivate of cost wrt activation
        dc_a2 = (self.a2 - y) * 2
        # derivate of activation wrt weighted input
        da2_z2 = d_relu_v(self.z2)
        # derivate of weighted input wrt to weights
        dz2_w2 = self.a1

        # Partial derivatives - hidden layer
        # derivate of output weighted input wrt hidden layer activation
        dz2_a1 = self.w2
        # derivate of activation wrt weighted input
        da1_z1 = d_relu_v(self.z1)
        # derivate of weighted input wrt weights
        dz1_w1 = self.a0

        # Matrix multiplication - Cost wrt weights - output layer
        p = (da2_z2 * dc_a2)
        g2 = dc_w2 = dz2_w2.T @ p

        # Matrix multiplication - Cost wrt weights - hidden layer
        dc_a1 = (p @ dz2_a1.T)
        dc_z1 = da1_z1 * dc_a1
        g1 = dc_w1 = dz1_w1.T @ dc_z1

        # Storing of weight adjustments
        self.w2_gradient += g2
        self.w1_gradient += g1

        # Storing of bias adjusments, cost with respect to bias
        self.b2_gradients += p * 1
        self.b1_gradients += dc_z1 * 1

    # relu function, returns 0 if the value is below zero, else it returns the value directly.
    # meaning always positive
    def relu(self, x):
        return max(0.0, x)

    # derivative of relu, if x > 0, return 1, else 0.
    def d_relu(self, x):
        return 1 * (x > 0)

    # sigmoid function
    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    # derivate of sigmoid
    def d_sigmoid(self, z):
        return self.sigmoid * (1 - self.sigmoid(z))

    # classify the data points in the sample
    def classify(self, x, y, batch_size):
        self.true_positive = 0
        self.true_negative = 0
        self.false_positive = 0
        self.false_negative = 0
        self.accuracy = 0

        # calculate batch count
        batch_count = int(x.shape[0] / batch_size)

        # split test data and labels into batches
        x_batch = np.split(x, batch_count)
        y_batch = np.split(y, batch_count)

        # iterate every batch
        for j in range(0, len(x_batch)):
            # feed forward the batch
            self.feed_forward(x_batch[j])

            # calulate the accuracy using the labels for the batch
            self.calculate_accuracy(self.a2, y_batch[j])
        
        classification_count = x.shape[0]
        test_waldo_count = np.count_nonzero(y[:,1] == 0)
        test_notwaldo_count = np.count_nonzero(y[:,1] == 1)

        # prevent division by zero when using lopsided testing samples.
        if test_waldo_count == 0:
            test_waldo_count = 1

        if test_notwaldo_count == 0:
            test_notwaldo_count = 1

        print("Neural Network with", self.a1.size, "hidden layer neurons")
        print("total accuracy: ", (self.accuracy / classification_count * 100, "%"))
        print("true_positive: ", (self.true_positive / test_waldo_count * 100, "%"))
        print("true_negative: ", (self.true_negative / test_notwaldo_count * 100, "%"))
        print("false_positive: ", (self.false_positive / test_notwaldo_count * 100, "%"))
        print("false_negative: ", (self.false_negative / test_waldo_count * 100, "%"))

    # cumulative function to calculate the accuracy stats of the network
    def calculate_accuracy(self, y_pred, y_true):
        self.true_positive += (y_pred.argmax(axis=1) == 0 and (y_pred.argmax(axis=1) == y_true.argmax(axis=1))).mean() 
        self.true_negative += (y_pred.argmax(axis=1) == 1 and (y_pred.argmax(axis=1) == y_true.argmax(axis=1))).mean()
        self.false_positive += (y_pred.argmax(axis=1) == 0 and (y_pred.argmax(axis=1) != y_true.argmax(axis=1))).mean()
        self.false_negative += (y_pred.argmax(axis=1) == 1 and (y_pred.argmax(axis=1) != y_true.argmax(axis=1))).mean()

        self.accuracy += (y_pred.argmax(axis=1) == y_true.argmax(axis=1)).mean()
        
    # mean squared error function
    def cost(self, output, expected_output):
        error = output - expected_output
        return error**2
     
    # loss function calculates the MSE over a batch
    def loss(self, y):
        # print("calculating average loss")
        loss = 0.0
        for i in range(0, y.shape[0]): # for every row in expected output
                loss += self.cost(self.a2, y[i]).sum()

        return loss / y.shape[0]

    # adjusts the biases and weights of the network by applying gradient descent.
    def apply_gradient_descent(self, learning_rate, learning_count):
        #weights
        np.copyto(self.w2, self.w2 - learning_rate * (self.w2_gradient / learning_count))
        np.copyto(self.w1, self.w1 - learning_rate * (self.w1_gradient / learning_count))

        #biases
        np.copyto(self.b2, self.b2 - learning_rate * (self.b2_gradients / learning_count))
        np.copyto(self.b1, self.b1 - learning_rate * (self.b1_gradients / learning_count))

    # resets the gradient matrices to their default values
    def reset_gradients(self):
        self.w1_gradient = np.zeros(shape=self.w1.shape)
        self.w2_gradient = np.zeros(shape=self.w2.shape)
        self.b1_gradients = np.zeros(shape=self.b1.shape)
        self.b2_gradients = np.zeros(shape=self.b2.shape)

    # main training function of the network. 
    # continues training the network # epochs using the specified batch size and learning rate
    def learn(self, x, y, batch_size, learning_rate, epochs):
        print("training network")

        # calcualte batch count
        batch_count = int(x.shape[0] / batch_size)

        # create panda data frame for storing MSE and accuracy over epochs
        results = pd.DataFrame(columns=["mse", "accuracy"])

        for i in range(0, epochs):

            x_batch = np.split(x, batch_count)
            y_batch = np.split(y, batch_count)

            self.true_positive = 0
            self.true_negative = 0
            self.false_positive = 0
            self.false_negative = 0
            self.accuracy = 0
            cost = 0

            for j in range(0, len(x_batch)):

                # feed forward the batch
                self.feed_forward(x_batch[j])

                # calculate gradients for every data point in the batch
                self.backpropagation(y_batch[j])

                # apply gradient descent to weights and biases using the stored gradients
                self.apply_gradient_descent(learning_rate, x_batch[j].size)

                # reset all the stored gradients
                self.reset_gradients()

                self.calculate_accuracy(self.a2, y_batch[j])

                cost = self.cost(self.a2, y_batch[j]).sum()

            # add mse and accuracy for the batch to the panda data frame for latter plotting
            new_stats = pd.DataFrame([(cost, self.accuracy / x.shape[0])], columns=["mse", "accuracy"])
            results = pd.concat([results, new_stats], ignore_index=True)

            print("epoch: ", i, " avg loss: ", self.loss(y))

            # save the bias and weights for each epoch allowing for early stop
            save_bias_weights(self)

        # plotting of mse and accuracy
        folder = "media/"

        plt.clf()
        plt.xlabel("Epochs")
        results.mse.plot(title="Mean Squared Error. Hidden layer size: {}".format(self.a1.size))
        plt.savefig(folder + "mse_hls{}_epochs{}.png".format(self.a1.size, epochs))

        plt.clf()
        plt.xlabel("Epochs")
        results.accuracy.plot(title="Accuracy. Hidden layer size: {}".format(self.a1.size))
        plt.savefig(folder + "acc_hls{}_epochs{}.png".format(self.a1.size, epochs))


def main():
    # waldo data
    # remainder becomes validation data. sum of data subsets must not exceed 100%
    x_train, x_test, x_valid, y_train, y_test, y_valid = load_waldo_data(training_size_percent=80, testing_size_percent=20)

    # iris data
    #x_train, x_test, y_train, y_test = load_iris_data()

    # XOR data 
    #x_train, y_train = load_xor_data()
    #x_test = x_train
    #y_test = y_train

    print('x_train.shape:', x_train.shape)
    print('y_train.shape:', y_train.shape)

    input_layer_size = x_train.shape[1]
    hidden_layer_count = 1
    output_layer_size = y_train.shape[1]
    batch_size = 1 # needs to be evenly divideable by training size
    learning_rate = 0.1 # Set your learning rate. 0.1 is a good starting point
    epochs = 50 # Set how many iterations you want to run the training for

    max_hidden_layer_size = 31
    hidden_layer_step_size = 4

    for i in range(2, max_hidden_layer_size, hidden_layer_step_size):
        print("Creating new network, hidden layer size:", i)
        NN = Network(input_layer_size, hidden_layer_count, i, output_layer_size, batch_size)
        load_bias_weights(NN)
        NN.learn(x_train, y_train, batch_size, learning_rate, epochs)
        NN.classify(x_test, y_test, batch_size)

main()